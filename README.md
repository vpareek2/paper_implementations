# paper_implementations
Machine Learning Paper implementations

Next
"ImageNet Classification with Deep Convolutional Neural Networks" (Krizhevsky et al., 2012)

Introduced AlexNet, which kickstarted the deep learning revolution in computer vision.


"Attention Is All You Need" (Vaswani et al., 2017)

Presented the Transformer architecture, fundamentally changing NLP and beyond.


"Generative Adversarial Networks" (Goodfellow et al., 2014)

Introduced GANs, revolutionizing generative modeling and synthetic data creation.


"Deep Residual Learning for Image Recognition" (He et al., 2016)

Presented ResNet, allowing for much deeper networks through skip connections.


"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding" (Devlin et al., 2018)

Introduced BERT, setting new standards for transfer learning in NLP.


"Long Short-Term Memory" (Hochreiter & Schmidhuber, 1997)

Described LSTMs, crucial for sequence modeling tasks before Transformers.


"Dropout: A Simple Way to Prevent Neural Networks from Overfitting" (Srivastava et al., 2014)

Introduced dropout, a key regularization technique widely used in deep learning.
